{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "A **parameter** is a **numerical value that describes a characteristic of an entire population**.\n",
        "\n",
        "### In simple terms:\n",
        "\n",
        "* It is **fixed** (does not change)\n",
        "* It is usually **unknown**\n",
        "* It is calculated from **population data**\n",
        "\n",
        "### Examples:\n",
        "\n",
        "* The **average height of all people in India**\n",
        "* The **true mean income of all employees in a company**\n",
        "* The **population proportion** of voters who support a candidate\n",
        "\n",
        "### In statistics:\n",
        "\n",
        "* Parameters are often denoted by **Greek letters**, such as:\n",
        "\n",
        "  * **μ (mu)** → population mean\n",
        "  * **σ (sigma)** → population standard deviation\n",
        "  * **p** → population proportion\n",
        "\n",
        "### Parameter vs Statistic:\n",
        "\n",
        "* **Parameter** → describes a **population**\n",
        "* **Statistic** → describes a **sample**\n"
      ],
      "metadata": {
        "id": "UH4BarD0R6Hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is correlation? What does negative correlation mean?\n",
        "\n",
        "### **What is correlation?**\n",
        "\n",
        "**Correlation** is a statistical measure that shows **how two variables are related**—that is, how changes in one variable are associated with changes in another.\n",
        "\n",
        "* It tells the **direction** and **strength** of a relationship.\n",
        "* The correlation value ranges from **–1 to +1**.\n",
        "\n",
        "### **What does negative correlation mean?**\n",
        "\n",
        "A **negative correlation** means that **when one variable increases, the other decreases**, and vice versa.\n",
        "\n",
        "### **Examples of negative correlation:**\n",
        "\n",
        "* As **price increases**, **demand decreases**\n",
        "* As **speed increases**, **time to reach a destination decreases**\n",
        "* As **exercise time increases**, **body fat percentage decreases**\n",
        "\n",
        "### **Types of correlation (quick view):**\n",
        "\n",
        "* **Positive correlation (+)**: Both variables move in the same direction\n",
        "* **Negative correlation (–)**: Variables move in opposite directions\n",
        "* **Zero correlation (0)**: No relationship between variables\n"
      ],
      "metadata": {
        "id": "9TZVLVGmSZ9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "### **Definition of Machine Learning**\n",
        "\n",
        "**Machine Learning (ML)** is a branch of Artificial Intelligence (AI) that enables computers to **learn from data and improve their performance automatically without being explicitly programmed**.\n",
        "\n",
        "In simple words, machines identify **patterns in data** and make **predictions or decisions** based on those patterns.\n",
        "\n",
        "---\n",
        "\n",
        "### **Main Components of Machine Learning**\n",
        "\n",
        "1. **Data**\n",
        "\n",
        "   * The most important component.\n",
        "   * Includes training data and testing data.\n",
        "   * Can be structured (tables) or unstructured (images, text).\n",
        "\n",
        "2. **Features**\n",
        "\n",
        "   * Individual measurable properties or variables in the data.\n",
        "   * Example: age, salary, marks, pixels in an image.\n",
        "\n",
        "3. **Model**\n",
        "\n",
        "   * A mathematical representation that learns patterns from data.\n",
        "   * Examples: Linear Regression, Decision Trees, Neural Networks.\n",
        "\n",
        "4. **Algorithm**\n",
        "\n",
        "   * The method used to train the model.\n",
        "   * Examples: Gradient Descent, k-NN, Backpropagation.\n",
        "\n",
        "5. **Training Process**\n",
        "\n",
        "   * The process of feeding data to the algorithm so the model can learn.\n",
        "   * Adjusts model parameters to minimize errors.\n",
        "\n",
        "6. **Evaluation**\n",
        "\n",
        "   * Measures how well the model performs.\n",
        "   * Examples: Accuracy, Precision, Recall, RMSE.\n",
        "\n",
        "7. **Prediction / Inference**\n",
        "\n",
        "   * Using the trained model to make predictions on new, unseen data.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "wxYxiYc2SqhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "**Loss value** measures **how far the model’s predictions are from the actual values**.\n",
        "\n",
        "* **Low loss** → predictions are close to actual values → **good model**\n",
        "* **High loss** → predictions are far from actual values → **poor model**\n",
        "* If loss **decreases during training**, the model is learning well\n",
        "* If loss **stays high or increases**, the model is not learning properly\n",
        "\n"
      ],
      "metadata": {
        "id": "gGwB-C_2S3rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. What are continuous and categorical variables?\n",
        "\n",
        "* **Continuous variables**: Numerical values that can take **any value within a range**.\n",
        "  *Example:* height, weight, temperature\n",
        "\n",
        "* **Categorical variables**: Variables that represent **distinct groups or categories**.\n",
        "  *Example:* gender, blood group, color, yes/no\n"
      ],
      "metadata": {
        "id": "9m7w5ofdTARa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "**Categorical variables** are handled in Machine Learning by **converting them into numerical form**, since ML models work with numbers.\n",
        "\n",
        "### **Common techniques (short):**\n",
        "\n",
        "* **Label Encoding** – Assigns a unique number to each category\n",
        "  *Example:* Low=0, Medium=1, High=2\n",
        "\n",
        "* **One-Hot Encoding** – Creates binary columns for each category\n",
        "  *Example:* Color → Red, Blue, Green (0/1 columns)\n",
        "\n",
        "* **Ordinal Encoding** – Used when categories have a meaningful order\n",
        "  *Example:* Poor < Average < Good\n",
        "\n",
        "* **Target Encoding** – Replaces categories with the mean of the target variable\n"
      ],
      "metadata": {
        "id": "Ou2GONzCTNzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. What do you mean by training and testing a dataset?\n",
        "\n",
        "* **Training dataset**: The portion of data used to **teach the model** by learning patterns and relationships.\n",
        "\n",
        "* **Testing dataset**: The portion of data used to **evaluate the model’s performance** on unseen data.\n"
      ],
      "metadata": {
        "id": "BbYLGqh7Ta7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is sklearn.preprocessing?\n",
        "\n",
        "**`sklearn.preprocessing`** is a module in **Scikit-learn** used to **prepare and transform data** before applying Machine Learning models.\n",
        "\n",
        "### **It is used for:**\n",
        "\n",
        "* **Scaling** features (StandardScaler, MinMaxScaler)\n",
        "* **Encoding categorical data** (LabelEncoder, OneHotEncoder)\n",
        "* **Normalizing** data\n",
        "* **Handling missing values** (SimpleImputer)\n"
      ],
      "metadata": {
        "id": "y9zJ-LlsTnYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is a Test set?\n",
        "\n",
        "A **test set** is a portion of the dataset used to **evaluate the performance of a trained machine learning model**.\n",
        "\n",
        "* It contains **unseen data**\n",
        "* It checks how well the model **generalizes**\n",
        "* It is **not used during training**\n"
      ],
      "metadata": {
        "id": "U9zI6tACTv0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "### **1. How do we split data for model fitting in Python?**\n",
        "\n",
        "We use **`train_test_split()`** from **`sklearn.model_selection`**.\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "* **80% training**, **20% testing** (common split)\n",
        "* `random_state` ensures reproducibility\n",
        "\n",
        "---\n",
        "\n",
        "### **2. How do you approach a Machine Learning problem? (Short)**\n",
        "\n",
        "1. Understand the problem\n",
        "2. Collect & clean data\n",
        "3. Perform feature engineering\n",
        "4. Split data (train/test)\n",
        "5. Select & train model\n",
        "6. Evaluate performance\n",
        "7. Tune & deploy\n",
        "\n"
      ],
      "metadata": {
        "id": "PzbWC3MbT3b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "We perform **Exploratory Data Analysis (EDA)** before fitting a model to:\n",
        "\n",
        "* **Understand the data** (structure, distributions, relationships)\n",
        "* **Identify missing values** and errors\n",
        "* **Detect outliers** and anomalies\n",
        "* **Check patterns and correlations**\n",
        "* **Decide proper preprocessing** (scaling, encoding, transformations)\n",
        "* **Choose the right model**\n"
      ],
      "metadata": {
        "id": "ztdRh5pgUKuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is correlation?\n",
        "\n",
        "**Correlation** is a statistical measure that shows **the strength and direction of the relationship between two variables**.\n",
        "\n",
        "* Values range from **–1 to +1**\n",
        "* **+1** → perfect positive relationship\n",
        "* **–1** → perfect negative relationship\n",
        "* **0** → no relationship\n"
      ],
      "metadata": {
        "id": "lX632YvrUa9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What does negative correlation mean?\n",
        "\n",
        "**Negative correlation** means that **two variables move in opposite directions**.\n",
        "\n",
        "* When one variable **increases**, the other **decreases**\n",
        "* When one variable **decreases**, the other **increases**\n",
        "\n",
        "**Example:**\n",
        "As **price increases**, **demand decreases**\n"
      ],
      "metadata": {
        "id": "BOMV45E3Ukuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "\n",
        "You can find correlation between variables in Python mainly using **Pandas** (and optionally NumPy).\n",
        "\n",
        "### Using Pandas\n",
        "\n",
        "```python\n",
        "df.corr()\n",
        "```\n",
        "\n",
        "* Computes the **correlation matrix** between numerical variables\n",
        "* Default method: **Pearson**\n",
        "\n",
        "### Specific methods\n",
        "\n",
        "```python\n",
        "df.corr(method='pearson')   # linear relationship\n",
        "df.corr(method='spearman')  # rank-based\n",
        "df.corr(method='kendall')   # ordinal data\n",
        "```\n",
        "\n",
        "### Between two columns\n",
        "\n",
        "```python\n",
        "df['col1'].corr(df['col2'])\n",
        "```\n"
      ],
      "metadata": {
        "id": "S9kM3ksvVTNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "### **What is causation?**\n",
        "\n",
        "**Causation** means that **one variable directly causes a change in another variable**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Difference between correlation and causation**\n",
        "\n",
        "| Correlation                            | Causation                               |\n",
        "| -------------------------------------- | --------------------------------------- |\n",
        "| Shows a relationship between variables | Shows a cause-and-effect relationship   |\n",
        "| Variables move together                | One variable directly affects the other |\n",
        "| Does **not** imply cause               | Implies direct cause                    |\n",
        "\n",
        "---\n",
        "\n",
        "### **Example**\n",
        "\n",
        "* **Correlation:** Ice cream sales and drowning incidents both increase in summer.\n",
        "* **Causation:** Hot weather causes more people to swim → increases drowning incidents.\n",
        "\n"
      ],
      "metadata": {
        "id": "XXeLt8giVZ5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "### **What is an Optimizer?**\n",
        "\n",
        "In Machine Learning and Deep Learning, an **optimizer** is an algorithm that **adjusts the model’s parameters (weights) to minimize the loss function** during training.\n",
        "\n",
        "* Goal: **Find the best weights** that make predictions accurate.\n",
        "* Works by updating weights based on **gradients** (from backpropagation in neural networks).\n",
        "\n",
        "---\n",
        "\n",
        "### **Types of Optimizers**\n",
        "\n",
        "1. **Gradient Descent (GD)**\n",
        "\n",
        "   * Updates weights using the **average gradient of the whole dataset**.\n",
        "   * **Pros:** Simple and stable.\n",
        "   * **Cons:** Slow for large datasets.\n",
        "   * **Example:** Linear regression using GD.\n",
        "\n",
        "2. **Stochastic Gradient Descent (SGD)**\n",
        "\n",
        "   * Updates weights using **one training example at a time**.\n",
        "   * **Pros:** Faster, can escape local minima.\n",
        "   * **Cons:** Noisy updates, can oscillate.\n",
        "   * **Example:** Neural network training on images.\n",
        "\n",
        "3. **Mini-batch Gradient Descent**\n",
        "\n",
        "   * Updates weights using a **small batch of data** instead of the full dataset.\n",
        "   * **Pros:** Balances stability and speed.\n",
        "   * **Example:** Training CNNs with batch size 32.\n",
        "\n",
        "4. **Momentum**\n",
        "\n",
        "   * Accelerates SGD by **adding a fraction of the previous update** to current update.\n",
        "   * **Pros:** Faster convergence, avoids oscillation.\n",
        "   * **Example:** Image classification models.\n",
        "\n",
        "5. **Adam (Adaptive Moment Estimation)**\n",
        "\n",
        "   * Combines **Momentum + RMSProp**; adapts learning rate for each parameter.\n",
        "   * **Pros:** Fast, widely used, works well in practice.\n",
        "   * **Example:** Most modern deep learning models like Transformers.\n",
        "\n",
        "6. **RMSProp**\n",
        "\n",
        "   * Adjusts learning rate based on **recent squared gradients**.\n",
        "   * **Pros:** Handles non-stationary objectives, good for RNNs.\n",
        "   * **Example:** LSTM for sequence prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "jg-VkOOMVqNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        "\n",
        "**`sklearn.linear_model`** is a module in **Scikit-learn** that provides **linear models** for regression and classification.\n",
        "\n",
        "### **Purpose:**\n",
        "\n",
        "To model the relationship between **independent variables (features)** and a **dependent variable (target)** using a **linear equation**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Common models in `sklearn.linear_model`**\n",
        "\n",
        "1. **LinearRegression** – Predicts a continuous target.\n",
        "\n",
        "   ```python\n",
        "   from sklearn.linear_model import LinearRegression\n",
        "   model = LinearRegression()\n",
        "   model.fit(X_train, y_train)\n",
        "   ```\n",
        "\n",
        "2. **LogisticRegression** – For binary/multi-class classification.\n",
        "\n",
        "   ```python\n",
        "   from sklearn.linear_model import LogisticRegression\n",
        "   model = LogisticRegression()\n",
        "   model.fit(X_train, y_train)\n",
        "   ```\n",
        "\n",
        "3. **Ridge & Lasso Regression** – Linear regression with **regularization** to prevent overfitting.\n",
        "\n",
        "   ```python\n",
        "   from sklearn.linear_model import Ridge, Lasso\n",
        "   ```\n",
        "\n",
        "4. **ElasticNet** – Combination of L1 (Lasso) and L2 (Ridge) regularization.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "5cGY855kV3Qu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "**`model.fit()`** is used to **train a machine learning model** on the given data.\n",
        "\n",
        "* It **learns patterns** from the training data and adjusts model parameters.\n",
        "\n",
        "### **Arguments:**\n",
        "\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "* **X_train** → features (input data)\n",
        "* **y_train** → target (output/labels)\n"
      ],
      "metadata": {
        "id": "dh72_jVyXgBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "**`model.predict()`** is used to **make predictions using a trained machine learning model**.\n",
        "\n",
        "* It uses the **learned patterns** from training to predict outputs for new data.\n",
        "\n",
        "### **Arguments:**\n",
        "\n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n",
        "* **X_test** → features of the data you want predictions for\n"
      ],
      "metadata": {
        "id": "bMwwMZLhXw8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.What are continuous and categorical variables?\n",
        "\n",
        "### **Continuous and Categorical Variables**\n",
        "\n",
        "1. **Continuous Variables:**\n",
        "\n",
        "* Can take **any numerical value** within a range.\n",
        "* Usually measurable quantities.\n",
        "* Examples: height, weight, temperature, salary\n",
        "\n",
        "2. **Categorical Variables:**\n",
        "\n",
        "* Represent **distinct groups or categories**.\n",
        "* Can be **nominal** (no order) or **ordinal** (ordered).\n",
        "* Examples: gender, blood group, color, education level\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "FLVd9RlLYAVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "### **What is Feature Scaling?**\n",
        "\n",
        "**Feature scaling** is the process of **rescaling numerical features** to a **similar range** so that no feature dominates others.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why it helps in Machine Learning:**\n",
        "\n",
        "1. **Faster convergence**\n",
        "\n",
        "   * Many algorithms (like Gradient Descent) converge faster when features are on a similar scale.\n",
        "\n",
        "2. **Improved accuracy**\n",
        "\n",
        "   * Models like **KNN, SVM, and Logistic Regression** are sensitive to feature scales.\n",
        "\n",
        "3. **Prevents bias**\n",
        "\n",
        "   * Ensures features with larger ranges don’t **dominate** the learning process.\n",
        "\n",
        "---\n",
        "\n",
        "### **Common techniques:**\n",
        "\n",
        "* **Min-Max Scaling:** scales values to [0, 1]\n",
        "* **Standardization (Z-score):** scales values to have mean = 0, std = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "qpDhejBOYgiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. How do we perform scaling in Python?\n",
        "\n",
        "We perform feature scaling in Python using **`sklearn.preprocessing`**.\n",
        "\n",
        "### **1. Standardization (Z-score)**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # fit to data and transform\n",
        "```\n",
        "\n",
        "* Scales data to **mean = 0** and **std = 1**\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Min-Max Scaling**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # scales to [0, 1]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. MaxAbs Scaling** (for data with negative values)\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "scaler = MaxAbsScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n"
      ],
      "metadata": {
        "id": "EbTsy3EmYqg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. **`sklearn.preprocessing`** is a module in **Scikit-learn** used to **prepare and transform data** before applying Machine Learning models.\n",
        "\n",
        "---\n",
        "\n",
        "### **What it does:**\n",
        "\n",
        "1. **Scaling features**\n",
        "\n",
        "   * `StandardScaler`, `MinMaxScaler`, `MaxAbsScaler`\n",
        "2. **Encoding categorical data**\n",
        "\n",
        "   * `LabelEncoder`, `OneHotEncoder`\n",
        "3. **Normalizing data**\n",
        "\n",
        "   * `Normalizer`\n",
        "4. **Handling missing values**\n",
        "\n",
        "   * `SimpleImputer`\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "E-gWwo3bZJdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "In Python, we split data for training and testing using **`train_test_split`** from **`sklearn.model_selection`**.\n",
        "\n",
        "### **Example:**\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X = features, y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "### **Explanation:**\n",
        "\n",
        "* **`X_train` / `y_train`** → data for **training the model**\n",
        "* **`X_test` / `y_test`** → data for **testing/evaluating the model**\n",
        "* **`test_size=0.2`** → 20% of data used for testing\n",
        "* **`random_state`** → ensures reproducibility\n",
        "\n"
      ],
      "metadata": {
        "id": "amSzJBi4ZUtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Explain data encoding?\n",
        "\n",
        "### **What is Data Encoding?**\n",
        "\n",
        "**Data encoding** is the process of **converting categorical (non-numeric) data into numerical format** so that machine learning models can process it.\n",
        "\n",
        "Most ML algorithms **cannot work with text labels** directly, so encoding is necessary.\n",
        "\n",
        "---\n",
        "\n",
        "### **Common Techniques for Data Encoding**\n",
        "\n",
        "1. **Label Encoding**\n",
        "\n",
        "   * Assigns a **unique integer** to each category.\n",
        "   * Example: `Red → 0, Blue → 1, Green → 2`\n",
        "   * Use: `sklearn.preprocessing.LabelEncoder`\n",
        "\n",
        "2. **One-Hot Encoding**\n",
        "\n",
        "   * Creates **binary columns** for each category.\n",
        "   * Example: Color → Red, Blue, Green\n",
        "\n",
        "     | Red | Blue | Green |\n",
        "     | --- | ---- | ----- |\n",
        "     | 1   | 0    | 0     |\n",
        "     | 0   | 1    | 0     |\n",
        "   * Use: `sklearn.preprocessing.OneHotEncoder` or `pd.get_dummies()`\n",
        "\n",
        "3. **Ordinal Encoding**\n",
        "\n",
        "   * Used for **ordered categories**.\n",
        "   * Example: `Low → 0, Medium → 1, High → 2`\n",
        "\n",
        "4. **Target Encoding**\n",
        "\n",
        "   * Replaces categories with the **mean of the target variable** for each category.\n",
        "   * Useful for categorical features in predictive models.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "F3n1rTyHZlOW"
      }
    }
  ]
}